from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import Activation, Dropout, Dense
from keras.utils import np_utils
import numpy as np

# 変数の宣言 --- (1)
classes = 3 # いくつに分類するか
data_size = 75 * 75 * 3 # 縦75×横75×3原色

# データを学習しモデルを評価する
def main():
  # データの読み込み --- (2)
#  data = np.load("./photo-min.npz")
  data = np.load("./photo.npz")
  X = data["X"] # --- 画像データ
  y = data["y"] # --- ラベルデータ
  # データを2次元に変形する --- (3)
  X = np.reshape(X, (-1, data_size))
  # 訓練データとテストデータに分割 --- (4)
  X_train, X_test, y_train, y_test = train_test_split(X, y)
  # モデルを訓練し評価 --- (5)
  model = train(X_train, y_train)
  model_eval(model, X_test, y_test)

# モデルを構築しデータを学習する
def train(X, y):
  # モデルの構築 --- (6)
  model = Sequential()
  model.add(Dense(units=64, input_dim=(data_size))) # --- (6.1)
  model.add(Activation('relu')) # --- (6.2)
  model.add(Dense(units=classes)) # --- (6.3)
  model.add(Activation('softmax')) # --- (6.4)
  model.compile(loss='sparse_categorical_crossentropy',optimizer='sgd', metrics=['accuracy'])
  model.fit(X, y, epochs=60) # データを学習 --- (7)
  
#  from keras.preprocessing.image import ImageDataGenerator
#  datagen = ImageDataGenerator(
#        featurewise_center=False,  # set input mean to 0 over the dataset
#        samplewise_center=False,  # set each sample mean to 0
#        featurewise_std_normalization=False,  # divide inputs by std of the dataset
#        samplewise_std_normalization=False,  # divide each input by its std
#        zca_whitening=False,  # apply ZCA whitening
#        rotation_range=40,  # randomly rotate images in the range (degrees, 0 to 180)
#        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)
#        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)
#        horizontal_flip=True,  # randomly flip images
#        shear_range=0.2,
#        zoom_range=0.2,
#        fill_mode='nearest',
#        vertical_flip=False)  # randomly flip images
#
#  # Compute quantities required for feature-wise normalization
#  # (std, mean, and principal components if ZCA whitening is applied).
#  datagen.fit(X)
#
#  # Fit the model on the batches generated by datagen.flow().
#  model.fit_generator(datagen.flow(X, y,
#                                  batch_size=batch_size),
#                                  epochs=num_epochs,
##                                  validation_data=(X, y),
#                                  steps_per_epoch=int(np.ceil(X.shape[0] / float(batch_size))),
#                                  workers=1)
  return model

# モデルを評価する 
def model_eval(model, X_test, y_test):
  score = model.evaluate(X_test, y_test) # --- (8)
  print('loss=', score[0])
  print('accuracy=', score[1])
  
if __name__ == "__main__":
  main()

